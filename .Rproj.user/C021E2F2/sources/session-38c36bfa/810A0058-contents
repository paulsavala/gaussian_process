# https://bookdown.org/rbg/surrogates/chap5.html#chap5library
library(dplyr)
library(tidyr)
library(ggplot2)

library(mvtnorm)
library(plgp)


# Generating from 1d GP ------------------------------------------------------
n = 100
# Column vector of 100 equally spaced values from 0 to 10
X = matrix(seq(0, 10, length=n), ncol=1)

# Distance matrix
D = plgp::distance(X)

# Construct the covariance matrix as exponentiated negative distance,
# and slightly increase the diagonal to ensure positive definite
eps = sqrt(.Machine$double.eps)
Sigma = exp(-D) + diag(eps, n)

# Generate a multivariate random normal (MVN) with mean zero and covariance Sigma
Y = mvtnorm::rmvnorm(1, sigma=Sigma) %>% t

# Plot the samples
ggplot() +
  geom_line(aes(x=X, y=Y)) +
  ggtitle('Random function under a GP prior')

# Correlation by distance (X)
ggplot() +
  geom_line(aes(x=X, y=exp(-X**2))) +
  ggtitle('Correlation by disatnce')

# Multiple realizations
Y = rmvnorm(3, sigma=Sigma) %>% t
df = data.frame(X=X)
df = cbind(df, data.frame(Y))
names(df) = c('X', 'Y1', 'Y2', 'Y3')
df.long = tidyr::pivot_longer(df, cols=starts_with('Y'))
df.long$name = as.factor(df.long$name)

ggplot(df.long) +
  geom_line(aes(x=X, y=value, color=name)) +
  ggtitle('Multiple realizations')

# Updating a 1d GP --------------------------------------------------
n = 8
X = matrix(seq(0, 2*pi, length=n), ncol=1)
y = sin(X)
D = distance(X)
Sigma = exp(-D) + diag(eps, ncol(D))

# New realizations XX
XX = matrix(seq(-0.5, 2*pi + 0.5, length=100), ncol=1)
DXX = distance(XX)
SXX = exp(-DXX) + diag(eps, ncol(DXX)) # Covariance matrix of XX

# Covariance between X and XX
DX = distance(XX, X)
SX = exp(-DX)

# Compute conditional mean and covariance of X, conditioned on observations XX
mup = SX %*% solve(Sigma) %*% y
Sigmap = SXX - SX %*% solve(Sigma) %*% t(SX)

# Generate observations using posterior
YY = rmvnorm(100, mup, Sigmap)

# Calculate 90% CI for posterior
q1 = mup + qnorm(0.05, mean=0, sd=sqrt(diag(Sigmap)))
q2 = mup + qnorm(0.95, mean=0, sd=sqrt(diag(Sigmap)))

# Prepare observations for plotting
df.XX = data.frame(XX)
df.YY = data.frame(YY %>% t)
names(df.YY) = sapply('Y', paste0, seq(1, ncol(YY)))
df = cbind(df.XX, df.YY)
df.long = pivot_longer(df, !XX)
df.long$name = as.factor(df.long$name)

# Plot observations
ggplot() +
  geom_line(data=df.long, aes(x=XX, y=value, group=name), color='gray', alpha=0.4) +
  geom_point(aes(x=X, y=y), size=5) +              # Original points
  geom_line(aes(x=XX, y=mup)) +                    # Posterior mean
  geom_line(aes(x=XX, y=sin(XX)), color='blue') +  # Posterior actual
  geom_line(aes(x=XX, y=q1), color='red', linetype='dashed') + # Lower CI bound
  geom_line(aes(x=XX, y=q2), color='red', linetype='dashed') + # Upper CI bound
  ggtitle('Posterior predictive distribution')


# Updating a 2d GP --------------------------------------------------------
# Load EPA data
epa.data = readRDS('data/df_data_12list.RDS')
# Single snapshot
epa.df = epa.data[[1]]
epa.df$case_cntl = NULL
epa.df$year = NULL
names(epa.df) = c('station_id', 'x', 'y', 'pm2_5')

# Convert to mean zero and standard deviation 1
epa.df$pm2_5 = epa.df$pm2_5 %>% scale

ggplot(epa.df) +
  geom_point(aes(x=x, y=y, color=pm2_5)) +
  scale_color_gradient2(low='blue', high='red', midpoint=0)

# Sample a small number of stations
epa.df.sample.idx = sample(1:nrow(epa.df), size=25)
epa.df.sample = epa.df[epa.df.sample.idx, ]

# Make a lattice of points across the US for predictions
x1 = seq(min(epa.df$x), max(epa.df$x), length=25)
x2 = seq(min(epa.df$y), max(epa.df$y), length=25)
X.lattice = expand.grid(x1, x2)

# Get X and y values for sample of stations
X.actual = epa.df.sample[, c('x', 'y')] %>% as.matrix
y.actual = epa.df.sample$pm2_5 %>% as.matrix(ncol=1)

# Compute covariance matrices
Sigma.actual = exp(-distance(X.actual)) + diag(eps, nrow(X.actual))
Sigma.lattice = exp(-distance(X.lattice)) + diag(eps, nrow(X.lattice))
Sigma.lattice_actual = exp(-distance(X.lattice, X.actual))

# Compute posterior mean and covariance matrix
mu.posterior = Sigma.lattice_actual %*% chol2inv(chol(Sigma.actual)) %*% y.actual
Sigma.posterior = Sigma.lattice - Sigma.lattice_actual %*% chol2inv(chol(Sigma.actual)) %*% t(Sigma.lattice_actual)
# Force to be symmetric (not symmetric due to rounding)
Sigma.posterior[lower.tri(Sigma.posterior)] = t(Sigma.posterior)[lower.tri(Sigma.posterior)]
# Force to be positive semi-definite
Sigma.posterior = Sigma.posterior + diag(0.01 + min(eigen(Sigma.posterior)$values), ncol(Sigma.posterior))

# Sample from MVN using posterior mean and covariance
YY = rmvnorm(n=100, mean=mu.posterior, sigma=Sigma.posterior)
YY.means = colMeans(YY)

# Prepare data for plotting
lattice.df = data.frame(X.lattice)
names(lattice.df) = c('x', 'y')
lattice.df$mean_pred = YY.means

# Plot actual and predicted
ggplot() +
  geom_point(data=epa.df, aes(x=x, y=y, color=pm2_5), size=3) +   # All measurements
  geom_point(data=lattice.df %>% filter(abs(mean_pred) < 4), aes(x=x, y=y, color=mean_pred), shape=18, size=2) + # Prediction
  scale_color_gradient2(low='blue', high='red', midpoint=0) +
  geom_point(data=epa.df.sample, aes(x=x, y=y), size=5) + # Stations
  ggtitle('Posterior predictive distribution')
